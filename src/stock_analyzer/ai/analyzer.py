"""
===================================
Aè‚¡è‡ªé€‰è‚¡æ™ºèƒ½åˆ†æç³»ç»Ÿ - AIåˆ†æå±‚
===================================

èŒè´£ï¼š
1. å°è£… Gemini API è°ƒç”¨é€»è¾‘
2. åˆ©ç”¨ Google Search Grounding è·å–å®æ—¶æ–°é—»
3. ç»“åˆæŠ€æœ¯é¢å’Œæ¶ˆæ¯é¢ç”Ÿæˆåˆ†ææŠ¥å‘Š
"""

import logging
import time
from typing import Any

from stock_analyzer.ai.clients import GeminiClient, OpenAIClient
from stock_analyzer.ai.prompt_builder import PromptBuilder
from stock_analyzer.ai.response_parser import ResponseParser
from stock_analyzer.ai.snapshot_builder import MarketSnapshotBuilder
from stock_analyzer.config import get_config
from stock_analyzer.domain import get_stock_name_from_context
from stock_analyzer.domain.entities.analysis_result import AnalysisResult
from stock_analyzer.domain.services.interfaces import IAIAnalyzer
from stock_analyzer.utils.fallback import create_sequential_fallback

logger = logging.getLogger(__name__)


class GeminiAnalyzer(IAIAnalyzer):
    """
    Gemini AI åˆ†æå™¨

    èŒè´£ï¼š
    1. è°ƒç”¨ Google Gemini API è¿›è¡Œè‚¡ç¥¨åˆ†æ
    2. ç»“åˆé¢„å…ˆæœç´¢çš„æ–°é—»å’ŒæŠ€æœ¯é¢æ•°æ®ç”Ÿæˆåˆ†ææŠ¥å‘Š
    3. è§£æ AI è¿”å›çš„ JSON æ ¼å¼ç»“æœ

    ä½¿ç”¨æ–¹å¼ï¼š
        analyzer = GeminiAnalyzer()
        result = analyzer.analyze(context, news_context)
    """

    def __init__(self, api_key: str | None = None):
        """
        åˆå§‹åŒ– AI åˆ†æå™¨

        ä¼˜å…ˆçº§ï¼šGemini > OpenAI å…¼å®¹ API

        Args:
            api_key: Gemini API Keyï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»é…ç½®è¯»å–ï¼‰
        """
        self._gemini_client = GeminiClient(api_key)
        self._openai_client = OpenAIClient()
        self._use_openai = False

        # å¦‚æœGeminiä¸å¯ç”¨ï¼Œæ£€æŸ¥OpenAI
        if not self._gemini_client.is_available():
            if self._openai_client.is_available():
                self._use_openai = True
                logger.info("ä½¿ç”¨ OpenAI å…¼å®¹ API ä½œä¸º AI åç«¯")
            else:
                logger.warning("æœªé…ç½®ä»»ä½• AI API Keyï¼ŒAI åˆ†æåŠŸèƒ½å°†ä¸å¯ç”¨")

    def is_available(self) -> bool:
        """æ£€æŸ¥åˆ†æå™¨æ˜¯å¦å¯ç”¨"""
        return self._gemini_client.is_available() or self._openai_client.is_available()

    def _call_api(self, prompt: str, generation_config: dict) -> str:
        """
        è°ƒç”¨ AI APIï¼Œä½¿ç”¨ç»Ÿä¸€çš„å›é€€ç­–ç•¥

        Args:
            prompt: æç¤ºè¯
            generation_config: ç”Ÿæˆé…ç½®

        Returns:
            å“åº”æ–‡æœ¬
        """
        if not self.is_available():
            raise Exception("æ²¡æœ‰å¯ç”¨çš„ AI å®¢æˆ·ç«¯")

        # å®šä¹‰ä¸»æ“ä½œå’Œå›é€€æ“ä½œ
        def call_gemini() -> str:
            return self._gemini_client.generate(prompt, generation_config)

        def call_openai() -> str:
            return self._openai_client.generate(prompt, generation_config)

        # æ ¹æ®é…ç½®å†³å®šä¸»æ“ä½œ
        if self._use_openai:
            # OpenAI ä¸ºä¸»ï¼ŒGemini ä¸ºå›é€€
            if self._gemini_client.is_available():
                fallback = create_sequential_fallback(name="ai_openai_fallback")
                return fallback.execute(call_openai, call_gemini)
            return call_openai()
        else:
            # Gemini ä¸ºä¸»ï¼ŒOpenAI ä¸ºå›é€€
            if self._openai_client.is_available():
                fallback = create_sequential_fallback(name="ai_gemini_fallback")
                return fallback.execute(call_gemini, call_openai)
            return call_gemini()

    def analyze(self, context: dict[str, Any], news_context: str | None = None) -> AnalysisResult:
        """
        åˆ†æå•åªè‚¡ç¥¨

        æµç¨‹ï¼š
        1. æ ¼å¼åŒ–è¾“å…¥æ•°æ®ï¼ˆæŠ€æœ¯é¢ + æ–°é—»ï¼‰
        2. è°ƒç”¨ Gemini APIï¼ˆå¸¦é‡è¯•å’Œæ¨¡å‹åˆ‡æ¢ï¼‰
        3. è§£æ JSON å“åº”
        4. è¿”å›ç»“æ„åŒ–ç»“æœ

        Args:
            context: ä» storage.get_analysis_context() è·å–çš„ä¸Šä¸‹æ–‡æ•°æ®
            news_context: é¢„å…ˆæœç´¢çš„æ–°é—»å†…å®¹ï¼ˆå¯é€‰ï¼‰

        Returns:
            AnalysisResult å¯¹è±¡
        """
        code = context.get("code", "Unknown")
        config = get_config()

        # è¯·æ±‚å‰å¢åŠ å»¶æ—¶
        request_delay = config.ai.gemini_request_delay
        if request_delay > 0:
            logger.debug(f"[LLM] è¯·æ±‚å‰ç­‰å¾… {request_delay:.1f} ç§’...")
            time.sleep(request_delay)

        # è·å–è‚¡ç¥¨åç§°
        name = context.get("stock_name")
        if not name or name.startswith("è‚¡ç¥¨"):
            if "realtime" in context and context["realtime"].get("name"):
                name = context["realtime"]["name"]
            else:
                name = get_stock_name_from_context(code, context)

        # å¦‚æœæ¨¡å‹ä¸å¯ç”¨ï¼Œè¿”å›é»˜è®¤ç»“æœ
        if not self.is_available():
            return AnalysisResult(
                code=code,
                name=name,
                sentiment_score=50,
                trend_prediction="éœ‡è¡",
                operation_advice="æŒæœ‰",
                confidence_level="ä½",
                analysis_summary="AI åˆ†æåŠŸèƒ½æœªå¯ç”¨ï¼ˆæœªé…ç½® API Keyï¼‰",
                risk_warning="è¯·é…ç½® Gemini API Key åé‡è¯•",
                success=False,
                error_message="Gemini API Key æœªé…ç½®",
            )

        try:
            # æ ¼å¼åŒ–è¾“å…¥
            prompt = PromptBuilder.build_analysis_prompt(context, name, news_context)

            # è·å–æ¨¡å‹åç§°
            model_name = "unknown"
            if self._use_openai:
                model_name = "openai-compatible"
            elif self._gemini_client._current_model_name:
                model_name = self._gemini_client._current_model_name

            logger.info(f"========== AI åˆ†æ {name}({code}) ==========")
            logger.info(f"[LLMé…ç½®] æ¨¡å‹: {model_name}")
            logger.info(f"[LLMé…ç½®] Prompt é•¿åº¦: {len(prompt)} å­—ç¬¦")
            logger.info(f"[LLMé…ç½®] æ˜¯å¦åŒ…å«æ–°é—»: {'æ˜¯' if news_context else 'å¦'}")

            # è®°å½•å®Œæ•´ prompt
            prompt_preview = prompt[:500] + "..." if len(prompt) > 500 else prompt
            logger.info(f"[LLM Prompt é¢„è§ˆ]\n{prompt_preview}")
            logger.debug(f"=== å®Œæ•´ Prompt ({len(prompt)}å­—ç¬¦) ===\n{prompt}\n=== End Prompt ===")

            # è®¾ç½®ç”Ÿæˆé…ç½®
            generation_config = {
                "temperature": config.ai.gemini_temperature,
                "max_output_tokens": 8192,
            }

            api_provider = "OpenAI" if self._use_openai else "Gemini"
            logger.info(f"[LLMè°ƒç”¨] å¼€å§‹è°ƒç”¨ {api_provider} API...")

            # ä½¿ç”¨å¸¦é‡è¯•çš„ API è°ƒç”¨
            start_time = time.time()
            response_text = self._call_api(prompt, generation_config)
            elapsed = time.time() - start_time

            logger.info(
                f"[LLMè¿”å›] {api_provider} API å“åº”æˆåŠŸ, è€—æ—¶ {elapsed:.2f}s, å“åº”é•¿åº¦ {len(response_text)} å­—ç¬¦"
            )

            # è®°å½•å“åº”é¢„è§ˆ
            response_preview = response_text[:300] + "..." if len(response_text) > 300 else response_text
            logger.info(f"[LLMè¿”å› é¢„è§ˆ]\n{response_preview}")
            logger.debug(
                f"=== {api_provider} å®Œæ•´å“åº” ({len(response_text)}å­—ç¬¦) ===\n{response_text}\n=== End Response ==="
            )

            # è§£æå“åº”
            result = ResponseParser.parse(response_text, code, name)
            result.raw_response = response_text
            result.search_performed = bool(news_context)
            result.market_snapshot = MarketSnapshotBuilder.build(context)

            logger.info(f"[LLMè§£æ] {name}({code}) åˆ†æå®Œæˆ: {result.trend_prediction}, è¯„åˆ† {result.sentiment_score}")

            return result

        except Exception as e:
            logger.error(f"AI åˆ†æ {name}({code}) å¤±è´¥: {e}")
            return AnalysisResult(
                code=code,
                name=name,
                sentiment_score=50,
                trend_prediction="éœ‡è¡",
                operation_advice="æŒæœ‰",
                confidence_level="ä½",
                analysis_summary=f"åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)[:100]}",
                risk_warning="åˆ†æå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•æˆ–æ‰‹åŠ¨åˆ†æ",
                success=False,
                error_message=str(e),
            )

    def batch_analyze(self, contexts: list[dict[str, Any]], delay_between: float = 2.0) -> list[AnalysisResult]:
        """
        æ‰¹é‡åˆ†æå¤šåªè‚¡ç¥¨

        Args:
            contexts: ä¸Šä¸‹æ–‡æ•°æ®åˆ—è¡¨
            delay_between: æ¯æ¬¡åˆ†æä¹‹é—´çš„å»¶è¿Ÿï¼ˆç§’ï¼‰

        Returns:
            AnalysisResult åˆ—è¡¨
        """
        results = []

        for i, context in enumerate(contexts):
            if i > 0:
                logger.debug(f"ç­‰å¾… {delay_between} ç§’åç»§ç»­...")
                time.sleep(delay_between)

            result = self.analyze(context)
            results.append(result)

        return results

    def generate_market_review(self, prompt: str, generation_config: dict[str, Any]) -> str | None:
        """
        ç”Ÿæˆå¸‚åœºå¤ç›˜æŠ¥å‘Š

        Args:
            prompt: æç¤ºè¯
            generation_config: ç”Ÿæˆé…ç½®

        Returns:
            ç”Ÿæˆçš„å¤ç›˜æŠ¥å‘Šæ–‡æœ¬ï¼Œå¤±è´¥è¿”å› None
        """
        try:
            return self._call_api(prompt, generation_config)
        except Exception as e:
            logger.error(f"ç”Ÿæˆå¸‚åœºå¤ç›˜æŠ¥å‘Šå¤±è´¥: {e}")
            return None


# ä¾¿æ·å‡½æ•°
def get_analyzer() -> GeminiAnalyzer:
    """è·å– Gemini åˆ†æå™¨å®ä¾‹"""
    return GeminiAnalyzer()


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.DEBUG)

    test_context = {
        "code": "600519",
        "date": "2026-01-09",
        "today": {
            "open": 1800.0,
            "high": 1850.0,
            "low": 1780.0,
            "close": 1820.0,
            "volume": 10000000,
            "amount": 18200000000,
            "pct_chg": 1.5,
            "ma5": 1810.0,
            "ma10": 1800.0,
            "ma20": 1790.0,
            "volume_ratio": 1.2,
        },
        "ma_status": "å¤šå¤´æ’åˆ— ğŸ“ˆ",
        "volume_change_ratio": 1.3,
        "price_change_ratio": 1.5,
    }

    analyzer = GeminiAnalyzer()

    if analyzer.is_available():
        print("=== AI åˆ†ææµ‹è¯• ===")
        result = analyzer.analyze(test_context)
        print(f"åˆ†æç»“æœ: {result.to_dict()}")
    else:
        print("Gemini API æœªé…ç½®ï¼Œè·³è¿‡æµ‹è¯•")
