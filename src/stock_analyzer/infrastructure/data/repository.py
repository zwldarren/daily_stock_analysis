"""
æ•°æ®åº“ä»“å‚¨å±‚

æä¾›æ•°æ®åº“è¿æ¥ç®¡ç†å’Œæ•°æ®è®¿é—®æ“ä½œ
"""

import atexit
import hashlib
import json
import logging
import re
from datetime import date, datetime, timedelta
from typing import TYPE_CHECKING, Any

import pandas as pd
from sqlalchemy import and_, create_engine, desc, select
from sqlalchemy.exc import IntegrityError
from sqlalchemy.orm import Session, sessionmaker

from stock_analyzer.config import get_config
from stock_analyzer.infrastructure.data.models import AnalysisHistory, Base, NewsIntel, StockDaily

if TYPE_CHECKING:
    from stock_analyzer.infrastructure.external.search.models import SearchResponse

logger = logging.getLogger(__name__)


class DatabaseManager:
    """
    æ•°æ®åº“ç®¡ç†å™¨ - å•ä¾‹æ¨¡å¼

    èŒè´£ï¼š
    1. ç®¡ç†æ•°æ®åº“è¿æ¥æ± 
    2. æä¾› Session ä¸Šä¸‹æ–‡ç®¡ç†
    3. å°è£…æ•°æ®å­˜å–æ“ä½œ
    """

    _instance: DatabaseManager | None = None

    def __new__(cls, *args, **kwargs):
        """å•ä¾‹æ¨¡å¼å®ç°"""
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def __init__(self, db_url: str | None = None):
        """
        åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨

        Args:
            db_url: æ•°æ®åº“è¿æ¥ URLï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»é…ç½®è¯»å–ï¼‰
        """
        if self._initialized:
            return

        if db_url is None:
            config = get_config()
            db_url = config.get_db_url()

        # åˆ›å»ºæ•°æ®åº“å¼•æ“
        self._engine = create_engine(
            db_url,
            echo=False,  # è®¾ä¸º True å¯æŸ¥çœ‹ SQL è¯­å¥
            pool_pre_ping=True,  # è¿æ¥å¥åº·æ£€æŸ¥
        )

        # åˆ›å»º Session å·¥å‚
        self._SessionLocal = sessionmaker(
            bind=self._engine,
            autocommit=False,
            autoflush=False,
        )

        # åˆ›å»ºæ‰€æœ‰è¡¨
        Base.metadata.create_all(self._engine)

        self._initialized = True
        logger.info(f"æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ: {db_url}")

        # æ³¨å†Œé€€å‡ºé’©å­ï¼Œç¡®ä¿ç¨‹åºé€€å‡ºæ—¶å…³é—­æ•°æ®åº“è¿æ¥
        atexit.register(DatabaseManager._cleanup_engine, self._engine)

    @classmethod
    def get_instance(cls) -> DatabaseManager:
        """è·å–å•ä¾‹å®ä¾‹"""
        if cls._instance is None:
            cls._instance = cls()
        return cls._instance

    @classmethod
    def reset_instance(cls) -> None:
        """é‡ç½®å•ä¾‹ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        if cls._instance is not None:
            cls._instance._engine.dispose()
            cls._instance = None

    @classmethod
    def _cleanup_engine(cls, engine) -> None:
        """
        æ¸…ç†æ•°æ®åº“å¼•æ“ï¼ˆatexit é’©å­ï¼‰

        ç¡®ä¿ç¨‹åºé€€å‡ºæ—¶å…³é—­æ‰€æœ‰æ•°æ®åº“è¿æ¥ï¼Œé¿å… ResourceWarning
        """
        try:
            if engine is not None:
                engine.dispose()
                logger.debug("æ•°æ®åº“å¼•æ“å·²æ¸…ç†")
        except Exception as e:
            logger.warning(f"æ¸…ç†æ•°æ®åº“å¼•æ“æ—¶å‡ºé”™: {e}")

    def get_session(self) -> Session:
        """
        è·å–æ•°æ®åº“ Session

        ä½¿ç”¨ç¤ºä¾‹:
            with db.get_session() as session:
                # æ‰§è¡ŒæŸ¥è¯¢
                session.commit()  # å¦‚æœéœ€è¦
        """
        session = self._SessionLocal()
        try:
            return session
        except Exception:
            session.close()
            raise

    def has_today_data(self, code: str, target_date: date | None = None) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦å·²æœ‰æŒ‡å®šæ—¥æœŸçš„æ•°æ®

        Args:
            code: è‚¡ç¥¨ä»£ç 
            target_date: ç›®æ ‡æ—¥æœŸï¼ˆé»˜è®¤ä»Šå¤©ï¼‰

        Returns:
            æ˜¯å¦å­˜åœ¨æ•°æ®
        """
        if target_date is None:
            target_date = date.today()

        with self.get_session() as session:
            result = session.execute(
                select(StockDaily).where(and_(StockDaily.code == code, StockDaily.date == target_date))
            ).scalar_one_or_none()

            return result is not None

    def get_latest_data(self, code: str, days: int = 2) -> list[StockDaily]:
        """
        è·å–æœ€è¿‘ N å¤©çš„æ•°æ®

        Args:
            code: è‚¡ç¥¨ä»£ç 
            days: è·å–å¤©æ•°

        Returns:
            StockDaily å¯¹è±¡åˆ—è¡¨ï¼ˆæŒ‰æ—¥æœŸé™åºï¼‰
        """
        with self.get_session() as session:
            results = (
                session.execute(
                    select(StockDaily).where(StockDaily.code == code).order_by(desc(StockDaily.date)).limit(days)
                )
                .scalars()
                .all()
            )

            return list(results)

    def get_daily_data(self, code: str, days: int = 30) -> pd.DataFrame | None:
        """
        è·å–æœ€è¿‘ N å¤©çš„æ—¥çº¿æ•°æ®

        Args:
            code: è‚¡ç¥¨ä»£ç 
            days: è·å–å¤©æ•°ï¼ˆé»˜è®¤30å¤©ï¼‰

        Returns:
            DataFrame åŒ…å«æ—¥çº¿æ•°æ®ï¼Œæˆ– None å¦‚æœæ²¡æœ‰æ•°æ®
        """
        records = self.get_latest_data(code, days)

        if not records:
            return None

        # è½¬æ¢ä¸º DataFrame
        data = [record.to_dict() for record in records]
        df = pd.DataFrame(data)

        # æŒ‰æ—¥æœŸå‡åºæ’åˆ—ï¼ˆä»æ—§åˆ°æ–°ï¼‰
        if "date" in df.columns:
            df = df.sort_values("date").reset_index(drop=True)

        return df

    def save_daily_data(self, df: pd.DataFrame, code: str, data_source: str = "Unknown") -> int:
        """
        ä¿å­˜æ—¥çº¿æ•°æ®åˆ°æ•°æ®åº“

        Args:
            df: åŒ…å«æ—¥çº¿æ•°æ®çš„ DataFrame
            code: è‚¡ç¥¨ä»£ç 
            data_source: æ•°æ®æ¥æºåç§°

        Returns:
            æ–°å¢/æ›´æ–°çš„è®°å½•æ•°
        """
        if df is None or df.empty:
            logger.warning(f"ä¿å­˜æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡ {code}")
            return 0

        saved_count = 0

        with self.get_session() as session:
            try:
                for _, row in df.iterrows():
                    # è§£ææ—¥æœŸ
                    row_date = row.get("date")
                    if isinstance(row_date, str):
                        row_date = datetime.strptime(row_date, "%Y-%m-%d").date()
                    elif isinstance(row_date, (datetime, pd.Timestamp)):
                        row_date = row_date.date()

                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                    existing = session.execute(
                        select(StockDaily).where(and_(StockDaily.code == code, StockDaily.date == row_date))
                    ).scalar_one_or_none()

                    if existing:
                        # æ›´æ–°ç°æœ‰è®°å½•
                        existing.open = row.get("open")
                        existing.high = row.get("high")
                        existing.low = row.get("low")
                        existing.close = row.get("close")
                        existing.volume = row.get("volume")
                        existing.amount = row.get("amount")
                        existing.pct_chg = row.get("pct_chg")
                        existing.ma5 = row.get("ma5")
                        existing.ma10 = row.get("ma10")
                        existing.ma20 = row.get("ma20")
                        existing.volume_ratio = row.get("volume_ratio")
                        existing.data_source = data_source
                        existing.updated_at = datetime.now()
                    else:
                        # åˆ›å»ºæ–°è®°å½•
                        record = StockDaily(
                            code=code,
                            date=row_date,
                            open=row.get("open"),
                            high=row.get("high"),
                            low=row.get("low"),
                            close=row.get("close"),
                            volume=row.get("volume"),
                            amount=row.get("amount"),
                            pct_chg=row.get("pct_chg"),
                            ma5=row.get("ma5"),
                            ma10=row.get("ma10"),
                            ma20=row.get("ma20"),
                            volume_ratio=row.get("volume_ratio"),
                            data_source=data_source,
                        )
                        session.add(record)
                        saved_count += 1

                session.commit()
                logger.info(f"ä¿å­˜ {code} æ•°æ®æˆåŠŸï¼Œæ–°å¢ {saved_count} æ¡")

            except Exception as e:
                session.rollback()
                logger.error(f"ä¿å­˜ {code} æ•°æ®å¤±è´¥: {e}")
                raise

        return saved_count

    def save_news_intel(
        self,
        code: str,
        name: str,
        dimension: str,
        query: str,
        response: SearchResponse,
        query_context: dict[str, str] | None = None,
    ) -> int:
        """
        ä¿å­˜æ–°é—»æƒ…æŠ¥åˆ°æ•°æ®åº“

        Args:
            code: è‚¡ç¥¨ä»£ç 
            name: è‚¡ç¥¨åç§°
            dimension: æœç´¢ç»´åº¦
            query: æœç´¢æŸ¥è¯¢
            response: æœç´¢å“åº”
            query_context: æŸ¥è¯¢ä¸Šä¸‹æ–‡

        Returns:
            ä¿å­˜çš„è®°å½•æ•°
        """
        if not response or not response.results:
            return 0

        saved_count = 0

        with self.get_session() as session:
            try:
                for item in response.results:
                    title = (item.title or "").strip()
                    url = (item.url or "").strip()
                    source = (item.source or "").strip()
                    snippet = (item.snippet or "").strip()
                    published_date = self._parse_published_date(item.published_date)

                    if not title and not url:
                        continue

                    url_key = url or self._build_fallback_url_key(
                        code=code, title=title, source=source, published_date=published_date
                    )

                    # ä¼˜å…ˆæŒ‰ URL æˆ–å…œåº•é”®å»é‡
                    existing = session.execute(select(NewsIntel).where(NewsIntel.url == url_key)).scalar_one_or_none()

                    if existing:
                        existing.name = name or existing.name
                        existing.dimension = dimension or existing.dimension
                        existing.query = query or existing.query
                        existing.provider = response.provider or existing.provider
                        existing.snippet = snippet or existing.snippet
                        existing.source = source or existing.source
                        existing.published_date = published_date or existing.published_date
                        existing.fetched_at = datetime.now()

                        if query_context:
                            existing.query_id = query_context.get("query_id") or existing.query_id
                            existing.query_source = query_context.get("query_source") or existing.query_source
                            existing.requester_platform = (
                                query_context.get("requester_platform") or existing.requester_platform
                            )
                            existing.requester_user_id = (
                                query_context.get("requester_user_id") or existing.requester_user_id
                            )
                            existing.requester_user_name = (
                                query_context.get("requester_user_name") or existing.requester_user_name
                            )
                            existing.requester_chat_id = (
                                query_context.get("requester_chat_id") or existing.requester_chat_id
                            )
                            existing.requester_message_id = (
                                query_context.get("requester_message_id") or existing.requester_message_id
                            )
                            existing.requester_query = query_context.get("requester_query") or existing.requester_query
                    else:
                        try:
                            with session.begin_nested():
                                record = NewsIntel(
                                    code=code,
                                    name=name,
                                    dimension=dimension,
                                    query=query,
                                    provider=response.provider,
                                    title=title,
                                    snippet=snippet,
                                    url=url_key,
                                    source=source,
                                    published_date=published_date,
                                    fetched_at=datetime.now(),
                                    query_id=(query_context or {}).get("query_id"),
                                    query_source=(query_context or {}).get("query_source"),
                                    requester_platform=(query_context or {}).get("requester_platform"),
                                    requester_user_id=(query_context or {}).get("requester_user_id"),
                                    requester_user_name=(query_context or {}).get("requester_user_name"),
                                    requester_chat_id=(query_context or {}).get("requester_chat_id"),
                                    requester_message_id=(query_context or {}).get("requester_message_id"),
                                    requester_query=(query_context or {}).get("requester_query"),
                                )
                                session.add(record)
                                session.flush()
                            saved_count += 1
                        except IntegrityError:
                            logger.debug("æ–°é—»æƒ…æŠ¥é‡å¤ï¼ˆå·²è·³è¿‡ï¼‰: %s %s", code, url_key)

                session.commit()
                logger.info(f"ä¿å­˜æ–°é—»æƒ…æŠ¥æˆåŠŸ: {code}, æ–°å¢ {saved_count} æ¡")

            except Exception as e:
                session.rollback()
                logger.error(f"ä¿å­˜æ–°é—»æƒ…æŠ¥å¤±è´¥: {e}")
                raise

        return saved_count

    def get_recent_news(self, code: str, days: int = 7, limit: int = 20) -> list[NewsIntel]:
        """
        è·å–æŒ‡å®šè‚¡ç¥¨æœ€è¿‘ N å¤©çš„æ–°é—»æƒ…æŠ¥
        """
        cutoff_date = datetime.now() - timedelta(days=days)

        with self.get_session() as session:
            results = (
                session.execute(
                    select(NewsIntel)
                    .where(and_(NewsIntel.code == code, NewsIntel.fetched_at >= cutoff_date))
                    .order_by(desc(NewsIntel.fetched_at))
                    .limit(limit)
                )
                .scalars()
                .all()
            )

            return list(results)

    def save_analysis_history(
        self,
        result: Any,
        query_id: str,
        report_type: str,
        news_content: str | None,
        context_snapshot: dict[str, Any] | None = None,
        save_snapshot: bool = True,
    ) -> int:
        """
        ä¿å­˜åˆ†æç»“æœå†å²è®°å½•
        """
        if result is None:
            return 0

        sniper_points = self._extract_sniper_points(result)
        raw_result = self._build_raw_result(result)
        context_text = None
        if save_snapshot and context_snapshot is not None:
            context_text = self._safe_json_dumps(context_snapshot)

        record = AnalysisHistory(
            query_id=query_id,
            code=result.code,
            name=result.name,
            report_type=report_type,
            sentiment_score=result.sentiment_score,
            operation_advice=result.operation_advice,
            trend_prediction=result.trend_prediction,
            analysis_summary=result.analysis_summary,
            raw_result=self._safe_json_dumps(raw_result),
            news_content=news_content,
            context_snapshot=context_text,
            ideal_buy=sniper_points.get("ideal_buy"),
            secondary_buy=sniper_points.get("secondary_buy"),
            stop_loss=sniper_points.get("stop_loss"),
            take_profit=sniper_points.get("take_profit"),
            created_at=datetime.now(),
        )

        with self.get_session() as session:
            try:
                session.add(record)
                session.commit()
                return 1
            except Exception as e:
                session.rollback()
                logger.error(f"ä¿å­˜åˆ†æå†å²å¤±è´¥: {e}")
                return 0

    def get_analysis_history(
        self,
        code: str | None = None,
        query_id: str | None = None,
        days: int = 30,
        limit: int = 50,
    ) -> list[AnalysisHistory]:
        """
        æŸ¥è¯¢åˆ†æå†å²è®°å½•
        """
        cutoff_date = datetime.now() - timedelta(days=days)

        with self.get_session() as session:
            conditions = [AnalysisHistory.created_at >= cutoff_date]
            if code:
                conditions.append(AnalysisHistory.code == code)
            if query_id:
                conditions.append(AnalysisHistory.query_id == query_id)

            results = (
                session.execute(
                    select(AnalysisHistory)
                    .where(and_(*conditions))
                    .order_by(desc(AnalysisHistory.created_at))
                    .limit(limit)
                )
                .scalars()
                .all()
            )

            return list(results)

    def get_data_range(self, code: str, start_date: date, end_date: date) -> list[StockDaily]:
        """
        è·å–æŒ‡å®šæ—¥æœŸèŒƒå›´çš„æ•°æ®
        """
        with self.get_session() as session:
            results = (
                session.execute(
                    select(StockDaily)
                    .where(
                        and_(
                            StockDaily.code == code,
                            StockDaily.date >= start_date,
                            StockDaily.date <= end_date,
                        )
                    )
                    .order_by(StockDaily.date)
                )
                .scalars()
                .all()
            )

            return list(results)

    def get_analysis_context(self, code: str, target_date: date | None = None) -> dict[str, Any] | None:
        """
        è·å–åˆ†ææ‰€éœ€çš„ä¸Šä¸‹æ–‡æ•°æ®

        è¿”å›ä»Šæ—¥æ•°æ® + æ˜¨æ—¥æ•°æ®çš„å¯¹æ¯”ä¿¡æ¯
        """
        if target_date is None:
            target_date = date.today()

        # è·å–æœ€è¿‘2å¤©æ•°æ®
        recent_data = self.get_latest_data(code, days=2)

        if not recent_data:
            logger.warning(f"æœªæ‰¾åˆ° {code} çš„æ•°æ®")
            return None

        today_data = recent_data[0]
        yesterday_data = recent_data[1] if len(recent_data) > 1 else None

        context = {
            "code": code,
            "date": today_data.date.isoformat(),
            "today": today_data.to_dict(),
        }

        if yesterday_data:
            context["yesterday"] = yesterday_data.to_dict()

            # è®¡ç®—ç›¸æ¯”æ˜¨æ—¥çš„å˜åŒ–
            if yesterday_data.volume and yesterday_data.volume > 0:
                context["volume_change_ratio"] = round(today_data.volume / yesterday_data.volume, 2)

            if yesterday_data.close and yesterday_data.close > 0:
                context["price_change_ratio"] = round(
                    (today_data.close - yesterday_data.close) / yesterday_data.close * 100, 2
                )

            # å‡çº¿å½¢æ€åˆ¤æ–­
            context["ma_status"] = self._analyze_ma_status(today_data)

        return context

    def _analyze_ma_status(self, data: StockDaily) -> str:
        """
        åˆ†æå‡çº¿å½¢æ€
        """
        close = data.close or 0
        ma5 = data.ma5 or 0
        ma10 = data.ma10 or 0
        ma20 = data.ma20 or 0

        if close > ma5 > ma10 > ma20 > 0:
            return "å¤šå¤´æ’åˆ— ğŸ“ˆ"
        elif close < ma5 < ma10 < ma20 and ma20 > 0:
            return "ç©ºå¤´æ’åˆ— ğŸ“‰"
        elif close > ma5 and ma5 > ma10:
            return "çŸ­æœŸå‘å¥½ ğŸ”¼"
        elif close < ma5 and ma5 < ma10:
            return "çŸ­æœŸèµ°å¼± ğŸ”½"
        else:
            return "éœ‡è¡æ•´ç† â†”ï¸"

    @staticmethod
    def _parse_published_date(value: str | None) -> datetime | None:
        """
        è§£æå‘å¸ƒæ—¶é—´å­—ç¬¦ä¸²
        """
        if not value:
            return None

        if isinstance(value, datetime):
            return value

        text = str(value).strip()
        if not text:
            return None

        # ä¼˜å…ˆå°è¯• ISO æ ¼å¼
        try:
            return datetime.fromisoformat(text)
        except ValueError:
            pass

        for fmt in (
            "%Y-%m-%d %H:%M:%S",
            "%Y-%m-%d %H:%M",
            "%Y-%m-%d",
            "%Y/%m/%d %H:%M:%S",
            "%Y/%m/%d %H:%M",
            "%Y/%m/%d",
        ):
            try:
                return datetime.strptime(text, fmt)
            except ValueError:
                continue

        return None

    @staticmethod
    def _safe_json_dumps(data: Any) -> str:
        """
        å®‰å…¨åºåˆ—åŒ–ä¸º JSON å­—ç¬¦ä¸²
        """
        try:
            return json.dumps(data, ensure_ascii=False, default=str)
        except Exception:
            return json.dumps(str(data), ensure_ascii=False)

    @staticmethod
    def _build_raw_result(result: Any) -> dict[str, Any]:
        """
        ç”Ÿæˆå®Œæ•´åˆ†æç»“æœå­—å…¸
        """
        data = result.to_dict() if hasattr(result, "to_dict") else {}
        data.update(
            {
                "data_sources": getattr(result, "data_sources", ""),
                "raw_response": getattr(result, "raw_response", None),
            }
        )
        return data

    @staticmethod
    def _parse_sniper_value(value: Any) -> float | None:
        """
        è§£æç‹™å‡»ç‚¹ä½æ•°å€¼
        """
        if value is None:
            return None
        if isinstance(value, (int, float)):
            return float(value)

        text = str(value).replace(",", "").strip()
        if not text:
            return None

        match = re.search(r"-?\d+(?:\.\d+)?", text)
        if not match:
            return None
        try:
            return float(match.group())
        except ValueError:
            return None

    def _extract_sniper_points(self, result: Any) -> dict[str, float | None]:
        """
        æŠ½å–ç‹™å‡»ç‚¹ä½æ•°æ®
        """
        raw_points = {}
        if hasattr(result, "get_sniper_points"):
            raw_points = result.get_sniper_points() or {}

        return {
            "ideal_buy": self._parse_sniper_value(raw_points.get("ideal_buy")),
            "secondary_buy": self._parse_sniper_value(raw_points.get("secondary_buy")),
            "stop_loss": self._parse_sniper_value(raw_points.get("stop_loss")),
            "take_profit": self._parse_sniper_value(raw_points.get("take_profit")),
        }

    @staticmethod
    def _build_fallback_url_key(code: str, title: str, source: str, published_date: datetime | None) -> str:
        """
        ç”Ÿæˆæ—  URL æ—¶çš„å»é‡é”®
        """
        date_str = published_date.isoformat() if published_date else ""
        raw_key = f"{code}|{title}|{source}|{date_str}"
        digest = hashlib.md5(raw_key.encode("utf-8")).hexdigest()
        return f"no-url:{code}:{digest}"


def get_db() -> DatabaseManager:
    """è·å–æ•°æ®åº“ç®¡ç†å™¨å®ä¾‹çš„å¿«æ·æ–¹å¼"""
    return DatabaseManager.get_instance()
